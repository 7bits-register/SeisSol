// Copyright (c) 2015, Intel Corporation
// 
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
// 
//     * Redistributions of source code must retain the above copyright notice,
//       this list of conditions and the following disclaimer.
//     * Redistributions in binary form must reproduce the above copyright
//       notice, this list of conditions and the following disclaimer in the
//       documentation and/or other materials provided with the distribution.
//     * Neither the name of the copyright holder nor the names of its contributors
//       may be used to endorse or promote products derived from this software
//       without specific prior written permission.
// 
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
// DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE
// FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
// DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
// SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
// OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
// 
// @file
// This file is part of SeisSol.
// 
// @author Alexander Breuer (breuer AT mytum.de, http://www5.in.tum.de/wiki/index.php/Dipl.-Math._Alexander_Breuer)
// @author Alexander Heinecke (alexander.heinecke AT mytum.de, http://www5.in.tum.de/wiki/index.php/Alexander_Heinecke,_M.Sc.,_M.Sc._with_honors)
// 
// @date 2015-11-21 13:46:33.652918
// 
// @section LICENSE
// Copyright (c) 2012-2015, SeisSol Group
// All rights reserved.
// 
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions are met:
// 
// 1. Redistributions of source code must retain the above copyright notice,
//    this list of conditions and the following disclaimer.
// 
// 2. Redistributions in binary form must reproduce the above copyright notice,
//    this list of conditions and the following disclaimer in the documentation
//    and/or other materials provided with the distribution.
// 
// 3. Neither the name of the copyright holder nor the names of its
//    contributors may be used to endorse or promote products derived from this
//    software without specific prior written permission.
// 
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
// AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
// ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE
// LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
// CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
// SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
// INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
// CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
// ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
// POSSIBILITY OF SUCH DAMAGE.
// 
// @section DESCRIPTION
// Remark: This file was generated.
#ifndef DGEMMWSMCPP
#define DGEMMWSMCPP

#if defined( __SSE3__) || defined(__MIC__)
#include <immintrin.h>
#endif

#include <cstddef>
#ifndef NDEBUG
extern long long libxsmm_num_total_flops;
#endif

void dgemm_m2_n9_k4_ldA4_ldB4_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $32, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $32, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $32, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $32, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $112, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 144;
#endif
}

void dgemm_m20_n9_k20_ldA20_ldB20_ldC20_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $3152, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $3184, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 7200;
#endif
}

void dgemm_m4_n9_k4_ldA4_ldB4_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $96, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 288;
#endif
}

void dgemm_m36_n9_k56_ldA56_ldB56_ldC36_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 288(%%rdx)\n\t"
                       "movapd %%xmm11, 304(%%rdx)\n\t"
                       "movapd %%xmm12, 320(%%rdx)\n\t"
                       "movapd %%xmm13, 576(%%rdx)\n\t"
                       "movapd %%xmm14, 592(%%rdx)\n\t"
                       "movapd %%xmm15, 608(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $25040, %%rdi\n\t"
                       "cmpq $36, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $576, %%rdx\n\t"
                       "addq $1344, %%rsi\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 36288;
#endif
}

void dgemm_m10_n9_k9_ldA10_ldB9_ldC10_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm7\n\t"
                       "movapd 16(%%rdx), %%xmm8\n\t"
                       "movapd 32(%%rdx), %%xmm9\n\t"
                       "movapd 80(%%rdx), %%xmm10\n\t"
                       "movapd 96(%%rdx), %%xmm11\n\t"
                       "movapd 112(%%rdx), %%xmm12\n\t"
                       "movapd 160(%%rdx), %%xmm13\n\t"
                       "movapd 176(%%rdx), %%xmm14\n\t"
                       "movapd 192(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $672, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm10\n\t"
                       "movapd 16(%%rdx), %%xmm11\n\t"
                       "movapd 80(%%rdx), %%xmm12\n\t"
                       "movapd 96(%%rdx), %%xmm13\n\t"
                       "movapd 160(%%rdx), %%xmm14\n\t"
                       "movapd 176(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $688, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 1620;
#endif
}

void dgemm_m56_n9_k9_ldA56_ldB9_ldC56_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm7\n\t"
                       "movapd 16(%%rdx), %%xmm8\n\t"
                       "movapd 32(%%rdx), %%xmm9\n\t"
                       "movapd 448(%%rdx), %%xmm10\n\t"
                       "movapd 464(%%rdx), %%xmm11\n\t"
                       "movapd 480(%%rdx), %%xmm12\n\t"
                       "movapd 896(%%rdx), %%xmm13\n\t"
                       "movapd 912(%%rdx), %%xmm14\n\t"
                       "movapd 928(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 448(%%rdx)\n\t"
                       "movapd %%xmm11, 464(%%rdx)\n\t"
                       "movapd %%xmm12, 480(%%rdx)\n\t"
                       "movapd %%xmm13, 896(%%rdx)\n\t"
                       "movapd %%xmm14, 912(%%rdx)\n\t"
                       "movapd %%xmm15, 928(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $3984, %%rdi\n\t"
                       "cmpq $54, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm13\n\t"
                       "movapd 448(%%rdx), %%xmm14\n\t"
                       "movapd 896(%%rdx), %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 448(%%rdx)\n\t"
                       "movapd %%xmm15, 896(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $4016, %%rdi\n\t"
                       "cmpq $56, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $896, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $448, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 9072;
#endif
}

void dgemm_m4_n9_k10_ldA56_ldB10_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $4448, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 720;
#endif
}

void dgemm_m4_n9_k4_ldA4_ldB4_ldC4_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "prefetcht1 32(%%r8)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "prefetcht1 64(%%r8)\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $32, %%r8\n\t"
                       "subq $96, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 288;
#endif
}

void dgemm_m56_n9_k84_ldA84_ldB84_ldC56_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $84, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $672, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 448(%%rdx)\n\t"
                       "movapd %%xmm11, 464(%%rdx)\n\t"
                       "movapd %%xmm12, 480(%%rdx)\n\t"
                       "movapd %%xmm13, 896(%%rdx)\n\t"
                       "movapd %%xmm14, 912(%%rdx)\n\t"
                       "movapd %%xmm15, 928(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $56400, %%rdi\n\t"
                       "cmpq $54, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $84, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $672, %%rsi\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 448(%%rdx)\n\t"
                       "movapd %%xmm15, 896(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $56432, %%rdi\n\t"
                       "cmpq $56, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $896, %%rdx\n\t"
                       "addq $2016, %%rsi\n\t"
                       "subq $448, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 84672;
#endif
}

void dgemm_m20_n9_k35_ldA20_ldB36_ldC20_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $5552, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $5584, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $864, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 12600;
#endif
}

void dgemm_m84_n9_k84_ldA84_ldB84_ldC84_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $84, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $672, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm10, 672(%%rdx)\n\t"
                       "movapd %%xmm11, 688(%%rdx)\n\t"
                       "movapd %%xmm12, 704(%%rdx)\n\t"
                       "prefetcht1 672(%%r8)\n\t"
                       "movapd %%xmm13, 1344(%%rdx)\n\t"
                       "movapd %%xmm14, 1360(%%rdx)\n\t"
                       "movapd %%xmm15, 1376(%%rdx)\n\t"
                       "prefetcht1 1344(%%r8)\n\t"
                       "addq $48, %%rdx\n\t"
                       "addq $48, %%r8\n\t"
                       "subq $56400, %%rdi\n\t"
                       "cmpq $84, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1344, %%rdx\n\t"
                       "addq $2016, %%rsi\n\t"
                       "subq $672, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 127008;
#endif
}

void dgemm_m2_n9_k0_ldA2_ldB2_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $-16, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $48, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 0;
#endif
}

void dgemm_m4_n9_k1_ldA4_ldB4_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $0, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 72;
#endif
}

void dgemm_m2_n9_k4_ldA36_ldB4_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $1136, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 144;
#endif
}

void dgemm_m4_n9_k10_ldA20_ldB10_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $1568, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 720;
#endif
}

void dgemm_m84_n9_k84_ldA84_ldB84_ldC84_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $84, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $672, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 672(%%rdx)\n\t"
                       "movapd %%xmm11, 688(%%rdx)\n\t"
                       "movapd %%xmm12, 704(%%rdx)\n\t"
                       "movapd %%xmm13, 1344(%%rdx)\n\t"
                       "movapd %%xmm14, 1360(%%rdx)\n\t"
                       "movapd %%xmm15, 1376(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $56400, %%rdi\n\t"
                       "cmpq $84, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1344, %%rdx\n\t"
                       "addq $2016, %%rsi\n\t"
                       "subq $672, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 127008;
#endif
}

void dgemm_m20_n9_k35_ldA84_ldB36_ldC20_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $23472, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $23504, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $864, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 12600;
#endif
}

void dgemm_m4_n9_k10_ldA10_ldB10_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $768, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 720;
#endif
}

void dgemm_m20_n9_k35_ldA56_ldB36_ldC20_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $15632, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $15664, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $864, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 12600;
#endif
}

void dgemm_m10_n9_k10_ldA10_ldB10_ldC10_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "prefetcht1 80(%%r8)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "prefetcht1 160(%%r8)\n\t"
                       "addq $48, %%rdx\n\t"
                       "addq $48, %%r8\n\t"
                       "subq $752, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "prefetcht1 80(%%r8)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "prefetcht1 160(%%r8)\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $32, %%r8\n\t"
                       "subq $768, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 1800;
#endif
}

void dgemm_m120_n9_k120_ldA120_ldB120_ldC120_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $120, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $960, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm10, 960(%%rdx)\n\t"
                       "movapd %%xmm11, 976(%%rdx)\n\t"
                       "movapd %%xmm12, 992(%%rdx)\n\t"
                       "prefetcht1 960(%%r8)\n\t"
                       "movapd %%xmm13, 1920(%%rdx)\n\t"
                       "movapd %%xmm14, 1936(%%rdx)\n\t"
                       "movapd %%xmm15, 1952(%%rdx)\n\t"
                       "prefetcht1 1920(%%r8)\n\t"
                       "addq $48, %%rdx\n\t"
                       "addq $48, %%r8\n\t"
                       "subq $115152, %%rdi\n\t"
                       "cmpq $120, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1920, %%rdx\n\t"
                       "addq $2880, %%rsi\n\t"
                       "subq $960, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 259200;
#endif
}

void dgemm_m2_n9_k4_ldA20_ldB4_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $624, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 144;
#endif
}

void dgemm_m2_n9_k9_ldA2_ldB9_ldC2_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm13\n\t"
                       "movapd 16(%%rdx), %%xmm14\n\t"
                       "movapd 32(%%rdx), %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $128, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 324;
#endif
}

void dgemm_m36_n9_k35_ldA36_ldB36_ldC36_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm10, 288(%%rdx)\n\t"
                       "movapd %%xmm11, 304(%%rdx)\n\t"
                       "movapd %%xmm12, 320(%%rdx)\n\t"
                       "prefetcht1 288(%%r8)\n\t"
                       "movapd %%xmm13, 576(%%rdx)\n\t"
                       "movapd %%xmm14, 592(%%rdx)\n\t"
                       "movapd %%xmm15, 608(%%rdx)\n\t"
                       "prefetcht1 576(%%r8)\n\t"
                       "addq $48, %%rdx\n\t"
                       "addq $48, %%r8\n\t"
                       "subq $10032, %%rdi\n\t"
                       "cmpq $36, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $576, %%rdx\n\t"
                       "addq $864, %%rsi\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 22680;
#endif
}

void dgemm_m10_n9_k20_ldA36_ldB20_ldC10_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $5712, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $5728, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 3600;
#endif
}

void dgemm_m10_n9_k4_ldA10_ldB10_ldC10_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $272, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 720;
#endif
}

void dgemm_m4_n9_k10_ldA84_ldB10_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $6688, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 720;
#endif
}

void dgemm_m36_n9_k56_ldA36_ldB56_ldC36_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 288(%%rdx)\n\t"
                       "movapd %%xmm11, 304(%%rdx)\n\t"
                       "movapd %%xmm12, 320(%%rdx)\n\t"
                       "movapd %%xmm13, 576(%%rdx)\n\t"
                       "movapd %%xmm14, 592(%%rdx)\n\t"
                       "movapd %%xmm15, 608(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $16080, %%rdi\n\t"
                       "cmpq $36, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $576, %%rdx\n\t"
                       "addq $1344, %%rsi\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 36288;
#endif
}

void dgemm_m4_n9_k9_ldA4_ldB9_ldC4_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm10\n\t"
                       "movapd 16(%%rdx), %%xmm11\n\t"
                       "movapd 32(%%rdx), %%xmm12\n\t"
                       "movapd 48(%%rdx), %%xmm13\n\t"
                       "movapd 64(%%rdx), %%xmm14\n\t"
                       "movapd 80(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $256, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 648;
#endif
}

void dgemm_m36_n9_k9_ldA36_ldB9_ldC36_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm7\n\t"
                       "movapd 16(%%rdx), %%xmm8\n\t"
                       "movapd 32(%%rdx), %%xmm9\n\t"
                       "movapd 288(%%rdx), %%xmm10\n\t"
                       "movapd 304(%%rdx), %%xmm11\n\t"
                       "movapd 320(%%rdx), %%xmm12\n\t"
                       "movapd 576(%%rdx), %%xmm13\n\t"
                       "movapd 592(%%rdx), %%xmm14\n\t"
                       "movapd 608(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 288(%%rdx)\n\t"
                       "movapd %%xmm11, 304(%%rdx)\n\t"
                       "movapd %%xmm12, 320(%%rdx)\n\t"
                       "movapd %%xmm13, 576(%%rdx)\n\t"
                       "movapd %%xmm14, 592(%%rdx)\n\t"
                       "movapd %%xmm15, 608(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $2544, %%rdi\n\t"
                       "cmpq $36, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $576, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 5832;
#endif
}

void dgemm_m2_n9_k1_ldA2_ldB2_ldC2_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 16(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 32(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "prefetcht1 16(%%r8)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "prefetcht1 32(%%r8)\n\t"
                       "addq $16, %%rdx\n\t"
                       "addq $16, %%r8\n\t"
                       "subq $0, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $48, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 36;
#endif
}

void dgemm_m4_n9_k10_ldA36_ldB10_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $2848, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 720;
#endif
}

void dgemm_m120_n9_k120_ldA120_ldB120_ldC120_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $120, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $960, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 960(%%rdx)\n\t"
                       "movapd %%xmm11, 976(%%rdx)\n\t"
                       "movapd %%xmm12, 992(%%rdx)\n\t"
                       "movapd %%xmm13, 1920(%%rdx)\n\t"
                       "movapd %%xmm14, 1936(%%rdx)\n\t"
                       "movapd %%xmm15, 1952(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $115152, %%rdi\n\t"
                       "cmpq $120, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1920, %%rdx\n\t"
                       "addq $2880, %%rsi\n\t"
                       "subq $960, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 259200;
#endif
}

void dgemm_m120_n9_k9_ldA120_ldB9_ldC120_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm7\n\t"
                       "movapd 16(%%rdx), %%xmm8\n\t"
                       "movapd 32(%%rdx), %%xmm9\n\t"
                       "movapd 960(%%rdx), %%xmm10\n\t"
                       "movapd 976(%%rdx), %%xmm11\n\t"
                       "movapd 992(%%rdx), %%xmm12\n\t"
                       "movapd 1920(%%rdx), %%xmm13\n\t"
                       "movapd 1936(%%rdx), %%xmm14\n\t"
                       "movapd 1952(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 960(%%rdx)\n\t"
                       "movapd %%xmm11, 976(%%rdx)\n\t"
                       "movapd %%xmm12, 992(%%rdx)\n\t"
                       "movapd %%xmm13, 1920(%%rdx)\n\t"
                       "movapd %%xmm14, 1936(%%rdx)\n\t"
                       "movapd %%xmm15, 1952(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $8592, %%rdi\n\t"
                       "cmpq $120, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1920, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $960, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 19440;
#endif
}

void dgemm_m20_n9_k20_ldA20_ldB20_ldC20_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "prefetcht1 160(%%r8)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "prefetcht1 320(%%r8)\n\t"
                       "addq $48, %%rdx\n\t"
                       "addq $48, %%r8\n\t"
                       "subq $3152, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "prefetcht1 160(%%r8)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "prefetcht1 320(%%r8)\n\t"
                       "addq $16, %%rdx\n\t"
                       "addq $16, %%r8\n\t"
                       "subq $3184, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 7200;
#endif
}

void dgemm_m2_n9_k4_ldA56_ldB4_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $1776, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 144;
#endif
}

void dgemm_m56_n9_k35_ldA56_ldB56_ldC56_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "movddup 704(%%rsi), %%xmm1\n\t"
                       "movddup 1152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "movddup 712(%%rsi), %%xmm1\n\t"
                       "movddup 1160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "movddup 720(%%rsi), %%xmm1\n\t"
                       "movddup 1168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 448(%%rdx)\n\t"
                       "movapd %%xmm11, 464(%%rdx)\n\t"
                       "movapd %%xmm12, 480(%%rdx)\n\t"
                       "movapd %%xmm13, 896(%%rdx)\n\t"
                       "movapd %%xmm14, 912(%%rdx)\n\t"
                       "movapd %%xmm15, 928(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $15632, %%rdi\n\t"
                       "cmpq $54, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 704(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1152(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 712(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1160(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 720(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1168(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 448(%%rdx)\n\t"
                       "movapd %%xmm15, 896(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $15664, %%rdi\n\t"
                       "cmpq $56, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $896, %%rdx\n\t"
                       "addq $1344, %%rsi\n\t"
                       "subq $448, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 35280;
#endif
}

void dgemm_m20_n9_k9_ldA20_ldB9_ldC20_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm7\n\t"
                       "movapd 16(%%rdx), %%xmm8\n\t"
                       "movapd 32(%%rdx), %%xmm9\n\t"
                       "movapd 160(%%rdx), %%xmm10\n\t"
                       "movapd 176(%%rdx), %%xmm11\n\t"
                       "movapd 192(%%rdx), %%xmm12\n\t"
                       "movapd 320(%%rdx), %%xmm13\n\t"
                       "movapd 336(%%rdx), %%xmm14\n\t"
                       "movapd 352(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $1392, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm13\n\t"
                       "movapd 160(%%rdx), %%xmm14\n\t"
                       "movapd 320(%%rdx), %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $1424, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 3240;
#endif
}

void dgemm_m2_n9_k1_ldA2_ldB2_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 16(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 32(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $0, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $48, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 36;
#endif
}

void dgemm_m10_n9_k20_ldA56_ldB20_ldC10_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $8912, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $8928, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 3600;
#endif
}

void dgemm_m120_n9_k84_ldA120_ldB120_ldC120_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $960, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $84, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $672, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 960(%%rdx)\n\t"
                       "movapd %%xmm11, 976(%%rdx)\n\t"
                       "movapd %%xmm12, 992(%%rdx)\n\t"
                       "movapd %%xmm13, 1920(%%rdx)\n\t"
                       "movapd %%xmm14, 1936(%%rdx)\n\t"
                       "movapd %%xmm15, 1952(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $80592, %%rdi\n\t"
                       "cmpq $120, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1920, %%rdx\n\t"
                       "addq $2880, %%rsi\n\t"
                       "subq $960, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 181440;
#endif
}

void dgemm_m10_n9_k20_ldA84_ldB20_ldC10_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $13392, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $13408, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 3600;
#endif
}

void dgemm_m10_n9_k10_ldA10_ldB10_ldC10_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $752, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $768, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 1800;
#endif
}

void dgemm_m84_n9_k9_ldA84_ldB9_ldC84_beta1_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "movapd 0(%%rdx), %%xmm7\n\t"
                       "movapd 16(%%rdx), %%xmm8\n\t"
                       "movapd 32(%%rdx), %%xmm9\n\t"
                       "movapd 672(%%rdx), %%xmm10\n\t"
                       "movapd 688(%%rdx), %%xmm11\n\t"
                       "movapd 704(%%rdx), %%xmm12\n\t"
                       "movapd 1344(%%rdx), %%xmm13\n\t"
                       "movapd 1360(%%rdx), %%xmm14\n\t"
                       "movapd 1376(%%rdx), %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 72(%%rsi), %%xmm1\n\t"
                       "movddup 144(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 152(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 672(%%rdx)\n\t"
                       "movapd %%xmm11, 688(%%rdx)\n\t"
                       "movapd %%xmm12, 704(%%rdx)\n\t"
                       "movapd %%xmm13, 1344(%%rdx)\n\t"
                       "movapd %%xmm14, 1360(%%rdx)\n\t"
                       "movapd %%xmm15, 1376(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $6000, %%rdi\n\t"
                       "cmpq $84, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1344, %%rdx\n\t"
                       "addq $216, %%rsi\n\t"
                       "subq $672, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 13608;
#endif
}

void dgemm_m4_n9_k10_ldA4_ldB10_ldC4_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 80(%%rsi), %%xmm1\n\t"
                       "movddup 160(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 88(%%rsi), %%xmm1\n\t"
                       "movddup 168(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 96(%%rsi), %%xmm1\n\t"
                       "movddup 176(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 104(%%rsi), %%xmm1\n\t"
                       "movddup 184(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 112(%%rsi), %%xmm1\n\t"
                       "movddup 192(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 120(%%rsi), %%xmm1\n\t"
                       "movddup 200(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 128(%%rsi), %%xmm1\n\t"
                       "movddup 208(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 136(%%rsi), %%xmm1\n\t"
                       "movddup 216(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 144(%%rsi), %%xmm1\n\t"
                       "movddup 224(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 152(%%rsi), %%xmm1\n\t"
                       "movddup 232(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $32, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 32(%%rdx)\n\t"
                       "movapd %%xmm13, 48(%%rdx)\n\t"
                       "movapd %%xmm14, 64(%%rdx)\n\t"
                       "movapd %%xmm15, 80(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $4, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $64, %%rdx\n\t"
                       "addq $240, %%rsi\n\t"
                       "subq $32, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 720;
#endif
}

void dgemm_m36_n9_k56_ldA84_ldB56_ldC36_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 288(%%rdx)\n\t"
                       "movapd %%xmm11, 304(%%rdx)\n\t"
                       "movapd %%xmm12, 320(%%rdx)\n\t"
                       "movapd %%xmm13, 576(%%rdx)\n\t"
                       "movapd %%xmm14, 592(%%rdx)\n\t"
                       "movapd %%xmm15, 608(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $37584, %%rdi\n\t"
                       "cmpq $36, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $576, %%rdx\n\t"
                       "addq $1344, %%rsi\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 36288;
#endif
}

void dgemm_m10_n9_k20_ldA10_ldB20_ldC10_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $1552, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $80, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $1568, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 3600;
#endif
}

void dgemm_m56_n9_k56_ldA56_ldB56_ldC56_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 448(%%rdx)\n\t"
                       "movapd %%xmm11, 464(%%rdx)\n\t"
                       "movapd %%xmm12, 480(%%rdx)\n\t"
                       "movapd %%xmm13, 896(%%rdx)\n\t"
                       "movapd %%xmm14, 912(%%rdx)\n\t"
                       "movapd %%xmm15, 928(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $25040, %%rdi\n\t"
                       "cmpq $54, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 448(%%rdx)\n\t"
                       "movapd %%xmm15, 896(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $25072, %%rdi\n\t"
                       "cmpq $56, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $896, %%rdx\n\t"
                       "addq $1344, %%rsi\n\t"
                       "subq $448, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 56448;
#endif
}

void dgemm_m2_n9_k4_ldA2_ldB4_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $16, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $48, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 144;
#endif
}

void dgemm_m36_n9_k35_ldA36_ldB36_ldC36_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 288(%%rdx)\n\t"
                       "movapd %%xmm11, 304(%%rdx)\n\t"
                       "movapd %%xmm12, 320(%%rdx)\n\t"
                       "movapd %%xmm13, 576(%%rdx)\n\t"
                       "movapd %%xmm14, 592(%%rdx)\n\t"
                       "movapd %%xmm15, 608(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $10032, %%rdi\n\t"
                       "cmpq $36, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $576, %%rdx\n\t"
                       "addq $864, %%rsi\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 22680;
#endif
}

void dgemm_m56_n9_k84_ldA56_ldB84_ldC56_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $84, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $672, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 448(%%rdx)\n\t"
                       "movapd %%xmm11, 464(%%rdx)\n\t"
                       "movapd %%xmm12, 480(%%rdx)\n\t"
                       "movapd %%xmm13, 896(%%rdx)\n\t"
                       "movapd %%xmm14, 912(%%rdx)\n\t"
                       "movapd %%xmm15, 928(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $37584, %%rdi\n\t"
                       "cmpq $54, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $84, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $672, %%rsi\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 448(%%rdx)\n\t"
                       "movapd %%xmm15, 896(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $37616, %%rdi\n\t"
                       "cmpq $56, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $896, %%rdx\n\t"
                       "addq $2016, %%rsi\n\t"
                       "subq $448, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 84672;
#endif
}

void dgemm_m20_n9_k35_ldA36_ldB36_ldC20_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $10032, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $32, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $256, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 256(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 544(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 832(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 264(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 552(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 840(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movddup 272(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 560(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 848(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $10064, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $864, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 12600;
#endif
}

void dgemm_m2_n9_k4_ldA10_ldB4_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $80, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $304, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 144;
#endif
}

void dgemm_m2_n9_k4_ldA84_ldB4_ldC2_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 32(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 64(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 40(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 72(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 48(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 80(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 56(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 88(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 16(%%rdx)\n\t"
                       "movapd %%xmm15, 32(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $2672, %%rdi\n\t"
                       "cmpq $2, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $32, %%rdx\n\t"
                       "addq $96, %%rsi\n\t"
                       "subq $16, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 144;
#endif
}

void dgemm_m84_n9_k56_ldA84_ldB84_ldC84_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 672(%%rsi), %%xmm1\n\t"
                       "movddup 1344(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 672(%%rdx)\n\t"
                       "movapd %%xmm11, 688(%%rdx)\n\t"
                       "movapd %%xmm12, 704(%%rdx)\n\t"
                       "movapd %%xmm13, 1344(%%rdx)\n\t"
                       "movapd %%xmm14, 1360(%%rdx)\n\t"
                       "movapd %%xmm15, 1376(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $37584, %%rdi\n\t"
                       "cmpq $84, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1344, %%rdx\n\t"
                       "addq $2016, %%rsi\n\t"
                       "subq $672, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 84672;
#endif
}

void dgemm_m20_n9_k10_ldA20_ldB20_ldC20_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 160(%%rdx)\n\t"
                       "movapd %%xmm11, 176(%%rdx)\n\t"
                       "movapd %%xmm12, 192(%%rdx)\n\t"
                       "movapd %%xmm13, 320(%%rdx)\n\t"
                       "movapd %%xmm14, 336(%%rdx)\n\t"
                       "movapd %%xmm15, 352(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $1552, %%rdi\n\t"
                       "cmpq $18, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 320(%%rdx)\n\t"
                       "addq $16, %%rdx\n\t"
                       "subq $1584, %%rdi\n\t"
                       "cmpq $20, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $320, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $160, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 3600;
#endif
}

void dgemm_m10_n9_k20_ldA20_ldB20_ldC10_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 80(%%rdx)\n\t"
                       "movapd %%xmm11, 96(%%rdx)\n\t"
                       "movapd %%xmm12, 112(%%rdx)\n\t"
                       "movapd %%xmm13, 160(%%rdx)\n\t"
                       "movapd %%xmm14, 176(%%rdx)\n\t"
                       "movapd %%xmm15, 192(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $3152, %%rdi\n\t"
                       "cmpq $6, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $4, %%r12\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 160(%%rsi), %%xmm1\n\t"
                       "movddup 320(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 168(%%rsi), %%xmm1\n\t"
                       "movddup 328(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 176(%%rsi), %%xmm1\n\t"
                       "movddup 336(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 184(%%rsi), %%xmm1\n\t"
                       "movddup 344(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 192(%%rsi), %%xmm1\n\t"
                       "movddup 352(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 200(%%rsi), %%xmm1\n\t"
                       "movddup 360(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 208(%%rsi), %%xmm1\n\t"
                       "movddup 368(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 216(%%rsi), %%xmm1\n\t"
                       "movddup 376(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 224(%%rsi), %%xmm1\n\t"
                       "movddup 384(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 232(%%rsi), %%xmm1\n\t"
                       "movddup 392(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 240(%%rsi), %%xmm1\n\t"
                       "movddup 400(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 248(%%rsi), %%xmm1\n\t"
                       "movddup 408(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 256(%%rsi), %%xmm1\n\t"
                       "movddup 416(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 264(%%rsi), %%xmm1\n\t"
                       "movddup 424(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 272(%%rsi), %%xmm1\n\t"
                       "movddup 432(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 280(%%rsi), %%xmm1\n\t"
                       "movddup 440(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 448(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 456(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 464(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 472(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd 16(%%rdi), %%xmm4\n\t"
                       "movapd %%xmm3, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm10\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm14\n\t"
                       "addq $160, %%rdi\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm0, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "movapd %%xmm5, %%xmm6\n\t"
                       "mulpd %%xmm1, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "mulpd %%xmm2, %%xmm6\n\t"
                       "addpd %%xmm6, %%xmm15\n\t"
                       "movapd %%xmm10, 0(%%rdx)\n\t"
                       "movapd %%xmm11, 16(%%rdx)\n\t"
                       "movapd %%xmm12, 80(%%rdx)\n\t"
                       "movapd %%xmm13, 96(%%rdx)\n\t"
                       "movapd %%xmm14, 160(%%rdx)\n\t"
                       "movapd %%xmm15, 176(%%rdx)\n\t"
                       "addq $32, %%rdx\n\t"
                       "subq $3168, %%rdi\n\t"
                       "cmpq $10, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $160, %%rdx\n\t"
                       "addq $480, %%rsi\n\t"
                       "subq $80, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 3600;
#endif
}

void dgemm_m56_n9_k56_ldA56_ldB56_ldC56_beta0_BL2viaC(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq %3, %%r8\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm10, 448(%%rdx)\n\t"
                       "movapd %%xmm11, 464(%%rdx)\n\t"
                       "movapd %%xmm12, 480(%%rdx)\n\t"
                       "prefetcht1 448(%%r8)\n\t"
                       "movapd %%xmm13, 896(%%rdx)\n\t"
                       "movapd %%xmm14, 912(%%rdx)\n\t"
                       "movapd %%xmm15, 928(%%rdx)\n\t"
                       "prefetcht1 896(%%r8)\n\t"
                       "addq $48, %%rdx\n\t"
                       "addq $48, %%r8\n\t"
                       "subq $25040, %%rdi\n\t"
                       "cmpq $54, %%r12\n\t"
                       "jl 1b\n\t"
                       "1:\n\t"
                       "addq $2, %%r12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "addq $448, %%rdi\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "mulpd %%xmm3, %%xmm0\n\t"
                       "addpd %%xmm0, %%xmm13\n\t"
                       "movddup 448(%%rsi), %%xmm1\n\t"
                       "mulpd %%xmm3, %%xmm1\n\t"
                       "addpd %%xmm1, %%xmm14\n\t"
                       "movddup 896(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "mulpd %%xmm3, %%xmm2\n\t"
                       "addpd %%xmm2, %%xmm15\n\t"
                       "cmpq $56, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $448, %%rsi\n\t"
                       "movapd %%xmm13, 0(%%rdx)\n\t"
                       "prefetcht1 0(%%r8)\n\t"
                       "movapd %%xmm14, 448(%%rdx)\n\t"
                       "prefetcht1 448(%%r8)\n\t"
                       "movapd %%xmm15, 896(%%rdx)\n\t"
                       "prefetcht1 896(%%r8)\n\t"
                       "addq $16, %%rdx\n\t"
                       "addq $16, %%r8\n\t"
                       "subq $25072, %%rdi\n\t"
                       "cmpq $56, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $896, %%rdx\n\t"
                       "addq $1344, %%rsi\n\t"
                       "subq $448, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C), "m"(B_prefetch) : "rdi","rsi","rdx","r8","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 56448;
#endif
}

void dgemm_m84_n9_k120_ldA84_ldB120_ldC84_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movq $0, %%r14\n\t"
                       "2:\n\t"
                       "addq $4, %%r14\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 960(%%rsi), %%xmm1\n\t"
                       "movddup 1920(%%rsi), %%xmm2\n\t"
                       "addq $8, %%rsi\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $672, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "cmpq $120, %%r14\n\t"
                       "jl 2b\n\t"
                       "subq $960, %%rsi\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 672(%%rdx)\n\t"
                       "movapd %%xmm11, 688(%%rdx)\n\t"
                       "movapd %%xmm12, 704(%%rdx)\n\t"
                       "movapd %%xmm13, 1344(%%rdx)\n\t"
                       "movapd %%xmm14, 1360(%%rdx)\n\t"
                       "movapd %%xmm15, 1376(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $80592, %%rdi\n\t"
                       "cmpq $84, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $1344, %%rdx\n\t"
                       "addq $2880, %%rsi\n\t"
                       "subq $672, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 181440;
#endif
}

void dgemm_m36_n9_k20_ldA36_ldB36_ldC36_beta0_pfsigonly(const double* A, const double* B, double* C, const double* A_prefetch, const double* B_prefetch, const double* C_prefetch) {
#ifdef __SSE3__
#ifdef __AVX__
#pragma message ("LIBXSMM KERNEL COMPILATION WARNING: compiling SSE3 code on AVX or newer architecture: " __FILE__)
#endif
  __asm__ __volatile__("movq %0, %%rsi\n\t"
                       "movq %1, %%rdi\n\t"
                       "movq %2, %%rdx\n\t"
                       "movq $0, %%r12\n\t"
                       "movq $0, %%r13\n\t"
                       "movq $0, %%r14\n\t"
                       "0:\n\t"
                       "addq $3, %%r13\n\t"
                       "movq $0, %%r12\n\t"
                       "1:\n\t"
                       "addq $6, %%r12\n\t"
                       "xorpd %%xmm7, %%xmm7\n\t"
                       "xorpd %%xmm8, %%xmm8\n\t"
                       "xorpd %%xmm9, %%xmm9\n\t"
                       "xorpd %%xmm10, %%xmm10\n\t"
                       "xorpd %%xmm11, %%xmm11\n\t"
                       "xorpd %%xmm12, %%xmm12\n\t"
                       "xorpd %%xmm13, %%xmm13\n\t"
                       "xorpd %%xmm14, %%xmm14\n\t"
                       "xorpd %%xmm15, %%xmm15\n\t"
                       "movddup 0(%%rsi), %%xmm0\n\t"
                       "movddup 288(%%rsi), %%xmm1\n\t"
                       "movddup 576(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 8(%%rsi), %%xmm0\n\t"
                       "movddup 296(%%rsi), %%xmm1\n\t"
                       "movddup 584(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 16(%%rsi), %%xmm0\n\t"
                       "movddup 304(%%rsi), %%xmm1\n\t"
                       "movddup 592(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 24(%%rsi), %%xmm0\n\t"
                       "movddup 312(%%rsi), %%xmm1\n\t"
                       "movddup 600(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 32(%%rsi), %%xmm0\n\t"
                       "movddup 320(%%rsi), %%xmm1\n\t"
                       "movddup 608(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 40(%%rsi), %%xmm0\n\t"
                       "movddup 328(%%rsi), %%xmm1\n\t"
                       "movddup 616(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 48(%%rsi), %%xmm0\n\t"
                       "movddup 336(%%rsi), %%xmm1\n\t"
                       "movddup 624(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 56(%%rsi), %%xmm0\n\t"
                       "movddup 344(%%rsi), %%xmm1\n\t"
                       "movddup 632(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 64(%%rsi), %%xmm0\n\t"
                       "movddup 352(%%rsi), %%xmm1\n\t"
                       "movddup 640(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 72(%%rsi), %%xmm0\n\t"
                       "movddup 360(%%rsi), %%xmm1\n\t"
                       "movddup 648(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 80(%%rsi), %%xmm0\n\t"
                       "movddup 368(%%rsi), %%xmm1\n\t"
                       "movddup 656(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 88(%%rsi), %%xmm0\n\t"
                       "movddup 376(%%rsi), %%xmm1\n\t"
                       "movddup 664(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 96(%%rsi), %%xmm0\n\t"
                       "movddup 384(%%rsi), %%xmm1\n\t"
                       "movddup 672(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 104(%%rsi), %%xmm0\n\t"
                       "movddup 392(%%rsi), %%xmm1\n\t"
                       "movddup 680(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 112(%%rsi), %%xmm0\n\t"
                       "movddup 400(%%rsi), %%xmm1\n\t"
                       "movddup 688(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 120(%%rsi), %%xmm0\n\t"
                       "movddup 408(%%rsi), %%xmm1\n\t"
                       "movddup 696(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 128(%%rsi), %%xmm0\n\t"
                       "movddup 416(%%rsi), %%xmm1\n\t"
                       "movddup 704(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 136(%%rsi), %%xmm0\n\t"
                       "movddup 424(%%rsi), %%xmm1\n\t"
                       "movddup 712(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 144(%%rsi), %%xmm0\n\t"
                       "movddup 432(%%rsi), %%xmm1\n\t"
                       "movddup 720(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movddup 152(%%rsi), %%xmm0\n\t"
                       "movddup 440(%%rsi), %%xmm1\n\t"
                       "movddup 728(%%rsi), %%xmm2\n\t"
                       "movapd 0(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm7\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm10\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm13\n\t"
                       "movapd 16(%%rdi), %%xmm3\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm8\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm11\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm14\n\t"
                       "movapd 32(%%rdi), %%xmm3\n\t"
                       "addq $288, %%rdi\n\t"
                       "movapd %%xmm3, %%xmm4\n\t"
                       "mulpd %%xmm0, %%xmm3\n\t"
                       "addpd %%xmm3, %%xmm9\n\t"
                       "movapd %%xmm4, %%xmm5\n\t"
                       "mulpd %%xmm1, %%xmm4\n\t"
                       "addpd %%xmm4, %%xmm12\n\t"
                       "mulpd %%xmm2, %%xmm5\n\t"
                       "addpd %%xmm5, %%xmm15\n\t"
                       "movapd %%xmm7, 0(%%rdx)\n\t"
                       "movapd %%xmm8, 16(%%rdx)\n\t"
                       "movapd %%xmm9, 32(%%rdx)\n\t"
                       "movapd %%xmm10, 288(%%rdx)\n\t"
                       "movapd %%xmm11, 304(%%rdx)\n\t"
                       "movapd %%xmm12, 320(%%rdx)\n\t"
                       "movapd %%xmm13, 576(%%rdx)\n\t"
                       "movapd %%xmm14, 592(%%rdx)\n\t"
                       "movapd %%xmm15, 608(%%rdx)\n\t"
                       "addq $48, %%rdx\n\t"
                       "subq $5712, %%rdi\n\t"
                       "cmpq $36, %%r12\n\t"
                       "jl 1b\n\t"
                       "addq $576, %%rdx\n\t"
                       "addq $864, %%rsi\n\t"
                       "subq $288, %%rdi\n\t"
                       "cmpq $9, %%r13\n\t"
                       "jl 0b\n\t"
                       : : "m"(B), "m"(A), "m"(C) : "rdi","rsi","rdx","r12","r13","r14","xmm0","xmm1","xmm2","xmm3","xmm4","xmm5","xmm6","xmm7","xmm8","xmm9","xmm10","xmm11","xmm12","xmm13","xmm14","xmm15");
#else
#pragma message ("LIBXSMM KERNEL COMPILATION ERROR in: " __FILE__)
#error No kernel was compiled, lacking support for current architecture?
#endif

#ifndef NDEBUG
#ifdef _OPENMP
#pragma omp atomic
#endif
libxsmm_num_total_flops += 12960;
#endif
}

#endif
